\section{Conclusions}

In this paper, we have presented \tool, a system for generating datasets for rule learning and for evaluating corresponding systems, in order to complement the existing evaluations, which are based on real KGs but missing rules. 
Our experiments on new, generated datasets have shown that 
\veronika{.}

There are various directions for future work. 
The dataset generation can be extended to more complex rules by including, for example, negation, existential quantification in rule heads, and functions.
Probabilistic rules as learned in \cite{Manhaeve+-NIPS18:deepproblog}, for example, are also interesting.
In the evaluation, we want to consider other measures, such as 
\cristina{\dots}
Our generated datasets can also be used -- and we plan to do so -- 
to develop neural rule learning approaches of a new kind, which are trained on several KGs and rules over them in order to suggest rules for previously unseen KGs later.
% In fact, this was the main motivation for developing \tool.
% 
% 
To the best of our knowledge, this direction has been unexplored to date, which means that the full potential of DL for learning rules has probably not been exploited yet.
% most likely because of the lack of data and rules to learn from.
% Such systems would be able to propose rules for KGs in arbitrary domains, which would make them a better fit for the real world.

\cristina{
TODO: future work
\begin{itemize}
    \item probabilistic reasoner
    \item more powerful logic (Full first order)
\end{itemize}
}